{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LstmCNN_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOmLD-tPgmfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()   \n",
        "drive = GoogleDrive(gauth)\n",
        "model.save('model.h5')\n",
        "model_file = drive.CreateFile({'title' : 'model.h5'})                \n",
        "model_file.SetContentFile('model.h5')                      \n",
        "model_file.Upload()\n",
        "drive.CreateFile({'id': model_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv-70dh9rtW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_obj = drive.CreateFile({'id': '1RXfXjPDVBkJxqUHBmOvyxHfpCj1yw-XO'})                       \n",
        "file_obj.GetContentFile('model_1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMDn_C4orsqx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roFL1PM1eOWZ",
        "colab_type": "code",
        "outputId": "e6f0a0a5-8179-42ef-d39a-89d153f35500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "import os\n",
        "import gzip\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.io.wavfile as wav\n",
        "import csv\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import IncrementalPCA, PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#kreas\n",
        "import tensorflow.keras as keras\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras import Input, layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from tensorflow.keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "#\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM0Zj-8Zj0iG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48BAhnhKS0_b",
        "colab_type": "code",
        "outputId": "795f60f3-8bbb-4389-f478-d2c080b993fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#đọc data\n",
        "#Vì đoạn vido khác ngắn nên ta cầng giảm n_mffc để nhận đc nhiều thông tin hơn\n",
        "data = pd.DataFrame(columns=['label', 'feature'])\n",
        "#data_dir = \"/content/gdrive/My Drive/TrainTmp/Train/\"\n",
        "data_dir = \"/content/gdrive/My Drive/Handout (1)/Train/Train/\"\n",
        "_len = 0\n",
        "input_duration = 3\n",
        "maxx = 0\n",
        "minn = 1000\n",
        "mean_signal_length = 32000  \n",
        "mfcc_len = 39\n",
        "with open('/content/gdrive/My Drive/Handout (1)/train_label.csv') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    next(csv_reader)    # bỏ qua dòng đầu tiên của file csv\n",
        "    for row in csv_reader:\n",
        "      _len += 1\n",
        "      \n",
        "      X, sample_rate = librosa.load(data_dir + row[0], res_type='kaiser_fast',duration=None,sr=22050*2,offset=0.0)\n",
        "      #X = noise(X)\n",
        "\n",
        "      X = shift(X)\n",
        "      #sample_rate, X = wav.read(data_dir + row[0])\n",
        "      #sample_rate = np.array(sample_rate)\n",
        "      mfccs = np.mean(librosa.feature.mfcc(y=X, sr=22050, n_mfcc=6), axis=0)\n",
        "      feature = mfccs\n",
        "      data.loc[_len, 'feature'] = feature\n",
        "      data.loc[_len, 'label'] = int(row[1])\n",
        "      maxx  = max(maxx, feature.shape[0])\n",
        "      minn  = min(minn, feature.shape[0])\n",
        "      print(_len)\n",
        "      \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88kOvKSMjcjn",
        "colab_type": "code",
        "outputId": "b48a0679-b715-4c28-94fa-aa0d85b929a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Read Test\n",
        "test = pd.DataFrame(columns=['label', 'feature'])\n",
        "test_dir = r\"/content/gdrive/My Drive/Public_Test/Public_Test/\"\n",
        "test_len = 0\n",
        "test_len_max = 157\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/gdrive/My Drive/Public_Test/Testfile.csv') as test_file:\n",
        "    test_reader = csv.reader(test_file, delimiter=',')\n",
        "    next(test_reader)\n",
        "    for row in test_reader:\n",
        "      test_len += 1\n",
        "      \n",
        "      X_test, test_sample_rate = librosa.load(test_dir + row[0], res_type='kaiser_fast',duration=None,sr=22050*2,offset=0.0)\n",
        "      test_mfccs = np.mean(librosa.feature.mfcc(y=X_test, sr=22050, n_mfcc=6), axis=0)\n",
        "      test_feature = test_mfccs\n",
        "      test.loc[test_len, 'feature'] = test_feature\n",
        "      test.loc[test_len, 'label'] = int(row[1])\n",
        "      test_len_max  = max(test_len_max, test_feature.shape[0])\n",
        "      print(test_len)\n",
        " \n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMmuP9yoluWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1, test_len + 1):\n",
        "  Tmp = np.zeros(maxx)\n",
        "  dat  = test['feature'].loc[i]\n",
        "\n",
        "  for j in range(dat.shape[0]):\n",
        "    Tmp[j] = dat[j]\n",
        "  test['feature'].loc[i] = Tmp\n",
        "  \n",
        "X_test = pd.DataFrame(test['feature'].values.tolist())\n",
        "X_test = np.array(X_test)\n",
        "Y_test = pd.DataFrame(test['label'].values.tolist())\n",
        "Y_test = np.array(Y_test)\n",
        "Y_test = np.resize(Y_test, test_len)\n",
        "X_test = np.resize(X_test, (test_len, maxx))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHMMdQUsqbGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOPTxFT4_Zl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xot3RBWKkLJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for i in range(1, _len + 1):\n",
        "  Tmp = np.zeros(maxx)\n",
        "  dat  = data['feature'].loc[i]\n",
        "\n",
        "  for j in range(dat.shape[0]):\n",
        "    Tmp[j] = dat[j]\n",
        "  data['feature'].loc[i] = Tmp\n",
        "\n",
        "X = pd.DataFrame(data['feature'].values.tolist())\n",
        "#X = np.array(data['feature'])\n",
        "#Y = np.array(data['label'])\n",
        "X = np.array(X)\n",
        "Y = pd.DataFrame(data['label'].values.tolist())\n",
        "Y = np.array(Y)\n",
        "Y = np.resize(Y, _len)\n",
        "X = np.resize(X, (_len, maxx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_5EdQB87Ct1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M750mWLCAnwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceZUKIY4_h0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsTdqov05iuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk5nVu6hIhAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PCA (Thu nghiem khong thanh cong)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=100).fit(X_scaled)\n",
        "X_pca = pca.transform(X_scaled)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLb_oP0g5wUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrlBIhZrIsyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzWEo_uWs07Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_time_series(data):\n",
        "    \"\"\"\n",
        "    Plot the Audio Frequency.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(14, 8))\n",
        "    plt.title('Raw wave ')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.plot(np.linspace(0, 1, len(data)), data)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def noise(data):\n",
        "    \"\"\"\n",
        "    Adding White Noise.\n",
        "    \"\"\"\n",
        "    # you can take any distribution from https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.random.html\n",
        "    noise_amp = 0.005*np.random.uniform()*np.amax(data)\n",
        "    data = data.astype('float64') + noise_amp * np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "    \n",
        "def shift(data):\n",
        "    \"\"\"\n",
        "    Random Shifting.\n",
        "    \"\"\"\n",
        "    s_range = int(np.random.uniform(low=-5, high = 5)*500)\n",
        "    return np.roll(data, s_range)\n",
        "    \n",
        "def stretch(data, rate=0.8):\n",
        "    \"\"\"\n",
        "    Streching the Sound.\n",
        "    \"\"\"\n",
        "    data = librosa.effects.time_stretch(data, rate)\n",
        "    return data\n",
        "    \n",
        "def pitch(data, sample_rate):\n",
        "    \"\"\"\n",
        "    Pitch Tuning.\n",
        "    \"\"\"\n",
        "    bins_per_octave = 12\n",
        "    pitch_pm = 2\n",
        "    pitch_change =  pitch_pm * 2*(np.random.uniform())   \n",
        "    data = librosa.effects.pitch_shift(data.astype('float64'), \n",
        "                                      sample_rate, n_steps=pitch_change, \n",
        "                                      bins_per_octave=bins_per_octave)\n",
        "    return data\n",
        "    \n",
        "def dyn_change(data):\n",
        "    \"\"\"\n",
        "    Random Value Change.\n",
        "    \"\"\"\n",
        "    dyn_change = np.random.uniform(low=1.5,high=3)\n",
        "    return (data * dyn_change)\n",
        "    \n",
        "def speedNpitch(data):\n",
        "    \"\"\"\n",
        "    peed and Pitch Tuning.\n",
        "    \"\"\"\n",
        "    # you can change low and high here\n",
        "    length_change = np.random.uniform(low=0.8, high = 1)\n",
        "    speed_fac = 1.0  / length_change\n",
        "    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n",
        "    minlen = min(data.shape[0], tmp.shape[0])\n",
        "    data *= 0\n",
        "    data[0:minlen] = tmp[0:minlen]\n",
        "    return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA4ooexCtRgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPR7tucolcve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state = 42, shuffle = True)\n",
        "\n",
        "#clf = SVC(kernel = 'rbf', probability=True)\n",
        "\n",
        "\n",
        "#clf.fit(X_train, y_train)\n",
        "\n",
        "#print(accuracy_score(clf.predict(X_val), y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNgCludcU8yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state = 42, shuffle = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVWxY9tMCNLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tach tap cho PCA\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_pca, Y, test_size = 0.2, random_state = 42, shuffle = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qomzx3xfM8LP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQdAkK_SMtkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm-OeSGnMu6b",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# CNN\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9QamgkOM-UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvY1raC3p-h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krOL6eBmPaqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#chuyển về dạng phù hợp cho CNN or LSTM+CNN\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "lb = LabelEncoder()\n",
        "y_traincnn = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_valcnn = np_utils.to_categorical(lb.fit_transform(y_val))\n",
        "Y_test = np_utils.to_categorical(lb.fit_transform(Y_test))\n",
        "\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_traincnn = np.expand_dims(X_train, axis=2)\n",
        "X_valcnn = np.expand_dims(X_val, axis=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4WXnk_3ooTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dQWwJfwYJWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "num_fc = 64\n",
        "batch_size = 32\n",
        "num_epochs = 150 #Chọn số bước train để được kết quả tốt nhất\n",
        "learning_rate = 0.0001\n",
        "decay = 1e-6\n",
        "\n",
        "momentum = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0CnLlULyb7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9iHSRxNZz97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaUOalmwuKgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wqn9zF9uh03",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcvUnSwTuKqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMp-vTXFPfLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def fscore(y_true, y_pred):\n",
        "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
        "        return 0\n",
        "\n",
        "    p = precision(y_true, y_pred)\n",
        "    r = recall(y_true, y_pred)\n",
        "    f_score = 2 * (p * r) / (p + r + K.epsilon())\n",
        "    return f_score\n",
        "\n",
        "def get_lr_metric(optimizer):\n",
        "    def lr(y_true, y_pred):\n",
        "        return optimizer.lr\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtznWZJOuNSg",
        "colab_type": "text"
      },
      "source": [
        "LTSM + CNN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bh1fZf7uM4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsHyiDtFNNh7",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Default title text\n",
        "#LSTM + CNN \n",
        "model = Sequential(name='Emo1DD')\n",
        "\t\n",
        "# LFLB1\n",
        "model.add(Conv1D(filters = 64,kernel_size = (3),strides=1,padding='same',data_format='channels_last',input_shape=(X_train.shape[1],1)))\t\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "\n",
        "\t#LFLB2\n",
        "model.add(Conv1D(filters=64, kernel_size = 3, strides=1,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "\n",
        "\t#LFLB3\n",
        "model.add(Conv1D(filters=128, kernel_size = 3, strides=1,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "\t#LFLB4\n",
        "model.add(Conv1D(filters=128, kernel_size = 3, strides=1,padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(MaxPooling1D(pool_size = 4, strides = 4))\n",
        "\n",
        "\t#LSTM\n",
        "model.add(LSTM(units=num_fc)) \n",
        "\t\t\n",
        "\t#FC\n",
        "model.add(Dense(units=6,activation='softmax'))\n",
        "\n",
        "\t#Model compilation\t\n",
        "opt = tf.keras.optimizers.SGD(lr = learning_rate, decay=decay, momentum=momentum, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', fscore])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baBHUUlp0bZu",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVD5FDJp2V0d",
        "colab_type": "text"
      },
      "source": [
        "CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ald3tJnQfgAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#CNN\n",
        "model = Sequential()\n",
        "model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(256, 8, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(64, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(64, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay= 1e-6, nesterov=False)\n",
        "#opt = tf.keras.optimizers.SGD(lr=1e-3, momentum=0.3, decay=0, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', fscore])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua-7XodVARXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OQSbR_X2Vqt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edM9xupD2XGD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7dTfnm9h7dO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsUNE4xzO61L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ9ffykhsetT",
        "colab_type": "code",
        "outputId": "faa7cd30-d96d-4e14-8b9f-49f5a9d80fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4183, 432)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COONqU4_OQpl",
        "colab_type": "code",
        "outputId": "4e39c080-7feb-43a3-fff4-6fe6511d820c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#mo hinh train chung cho cac model\n",
        "\n",
        "es = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8)\n",
        "#mc = ModelCheckpoint('best_model.h5', monitor='val_categorical_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "mc = ModelCheckpoint('model_1.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "history = model.fit(X_traincnn, y_traincnn,epochs=num_epochs,batch_size=batch_size,validation_data=(X_valcnn,y_valcnn),callbacks=[es, mc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4183 samples, validate on 1046 samples\n",
            "Epoch 1/100\n",
            "4183/4183 [==============================] - 12s 3ms/sample - loss: 1.7810 - acc: 0.1884 - fscore: 0.0000e+00 - val_loss: 1.7858 - val_acc: 0.1692 - val_fscore: 0.0000e+00\n",
            "Epoch 2/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.7411 - acc: 0.2450 - fscore: 0.0000e+00 - val_loss: 1.7479 - val_acc: 0.2266 - val_fscore: 0.0000e+00\n",
            "Epoch 3/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.7123 - acc: 0.2986 - fscore: 0.0000e+00 - val_loss: 1.7139 - val_acc: 0.2811 - val_fscore: 0.0000e+00\n",
            "Epoch 4/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.6871 - acc: 0.3359 - fscore: 0.0000e+00 - val_loss: 1.6877 - val_acc: 0.3222 - val_fscore: 0.0000e+00\n",
            "Epoch 5/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.6649 - acc: 0.3488 - fscore: 0.0000e+00 - val_loss: 1.6675 - val_acc: 0.3375 - val_fscore: 0.0000e+00\n",
            "Epoch 6/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.6441 - acc: 0.3562 - fscore: 0.0000e+00 - val_loss: 1.6497 - val_acc: 0.3308 - val_fscore: 0.0000e+00\n",
            "Epoch 7/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.6269 - acc: 0.3584 - fscore: 0.0000e+00 - val_loss: 1.6341 - val_acc: 0.3365 - val_fscore: 0.0000e+00\n",
            "Epoch 8/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.6098 - acc: 0.3593 - fscore: 0.0000e+00 - val_loss: 1.6195 - val_acc: 0.3317 - val_fscore: 0.0000e+00\n",
            "Epoch 9/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.5965 - acc: 0.3567 - fscore: 0.0000e+00 - val_loss: 1.6063 - val_acc: 0.3384 - val_fscore: 0.0000e+00\n",
            "Epoch 10/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.5803 - acc: 0.3715 - fscore: 0.0000e+00 - val_loss: 1.5947 - val_acc: 0.3394 - val_fscore: 0.0000e+00\n",
            "Epoch 11/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.5717 - acc: 0.3655 - fscore: 9.2528e-04 - val_loss: 1.5812 - val_acc: 0.3537 - val_fscore: 0.0000e+00\n",
            "Epoch 12/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.5597 - acc: 0.3715 - fscore: 0.0042 - val_loss: 1.5741 - val_acc: 0.3604 - val_fscore: 0.0037\n",
            "Epoch 13/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.5502 - acc: 0.3727 - fscore: 0.0097 - val_loss: 1.5633 - val_acc: 0.3614 - val_fscore: 0.0110\n",
            "Epoch 14/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.5420 - acc: 0.3744 - fscore: 0.0189 - val_loss: 1.5544 - val_acc: 0.3642 - val_fscore: 0.0227\n",
            "Epoch 15/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.5312 - acc: 0.3808 - fscore: 0.0344 - val_loss: 1.5475 - val_acc: 0.3671 - val_fscore: 0.0360\n",
            "Epoch 16/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.5233 - acc: 0.3847 - fscore: 0.0517 - val_loss: 1.5467 - val_acc: 0.3604 - val_fscore: 0.0425\n",
            "Epoch 17/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.5153 - acc: 0.3894 - fscore: 0.0671 - val_loss: 1.5386 - val_acc: 0.3872 - val_fscore: 0.0522\n",
            "Epoch 18/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.5088 - acc: 0.3947 - fscore: 0.0758 - val_loss: 1.5273 - val_acc: 0.3738 - val_fscore: 0.0642\n",
            "Epoch 19/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.5034 - acc: 0.3906 - fscore: 0.0890 - val_loss: 1.5249 - val_acc: 0.3834 - val_fscore: 0.0772\n",
            "Epoch 20/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4983 - acc: 0.3988 - fscore: 0.1006 - val_loss: 1.5189 - val_acc: 0.3891 - val_fscore: 0.0962\n",
            "Epoch 21/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4921 - acc: 0.3956 - fscore: 0.1082 - val_loss: 1.5155 - val_acc: 0.3920 - val_fscore: 0.0947\n",
            "Epoch 22/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4874 - acc: 0.4000 - fscore: 0.1197 - val_loss: 1.5095 - val_acc: 0.3824 - val_fscore: 0.1170\n",
            "Epoch 23/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4821 - acc: 0.4069 - fscore: 0.1302 - val_loss: 1.5097 - val_acc: 0.3901 - val_fscore: 0.1131\n",
            "Epoch 24/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4761 - acc: 0.4055 - fscore: 0.1332 - val_loss: 1.4999 - val_acc: 0.3843 - val_fscore: 0.1238\n",
            "Epoch 25/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.4740 - acc: 0.4071 - fscore: 0.1356 - val_loss: 1.5146 - val_acc: 0.3843 - val_fscore: 0.1215\n",
            "Epoch 26/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.4706 - acc: 0.4055 - fscore: 0.1468 - val_loss: 1.4952 - val_acc: 0.3910 - val_fscore: 0.1473\n",
            "Epoch 27/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4634 - acc: 0.4102 - fscore: 0.1534 - val_loss: 1.4902 - val_acc: 0.3939 - val_fscore: 0.1420\n",
            "Epoch 28/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4580 - acc: 0.4136 - fscore: 0.1605 - val_loss: 1.4903 - val_acc: 0.3901 - val_fscore: 0.1581\n",
            "Epoch 29/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.4551 - acc: 0.4160 - fscore: 0.1669 - val_loss: 1.4854 - val_acc: 0.3901 - val_fscore: 0.1577\n",
            "Epoch 30/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4520 - acc: 0.4157 - fscore: 0.1680 - val_loss: 1.4912 - val_acc: 0.3996 - val_fscore: 0.1490\n",
            "Epoch 31/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.4464 - acc: 0.4234 - fscore: 0.1721 - val_loss: 1.4808 - val_acc: 0.4044 - val_fscore: 0.1691\n",
            "Epoch 32/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.4426 - acc: 0.4124 - fscore: 0.1771 - val_loss: 1.4775 - val_acc: 0.3948 - val_fscore: 0.1746\n",
            "Epoch 33/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.4404 - acc: 0.4224 - fscore: 0.1808 - val_loss: 1.4738 - val_acc: 0.3948 - val_fscore: 0.1756\n",
            "Epoch 34/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.4373 - acc: 0.4260 - fscore: 0.1844 - val_loss: 1.4824 - val_acc: 0.3967 - val_fscore: 0.1615\n",
            "Epoch 35/100\n",
            "4183/4183 [==============================] - 8s 2ms/sample - loss: 1.4347 - acc: 0.4219 - fscore: 0.1862 - val_loss: 1.4742 - val_acc: 0.4063 - val_fscore: 0.1727\n",
            "Epoch 36/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.4315 - acc: 0.4243 - fscore: 0.1914 - val_loss: 1.4678 - val_acc: 0.3967 - val_fscore: 0.1607\n",
            "Epoch 37/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4259 - acc: 0.4289 - fscore: 0.1943 - val_loss: 1.4652 - val_acc: 0.3967 - val_fscore: 0.1843\n",
            "Epoch 38/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4215 - acc: 0.4270 - fscore: 0.1882 - val_loss: 1.4729 - val_acc: 0.3910 - val_fscore: 0.2147\n",
            "Epoch 39/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4189 - acc: 0.4332 - fscore: 0.2051 - val_loss: 1.4629 - val_acc: 0.4034 - val_fscore: 0.1931\n",
            "Epoch 40/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4154 - acc: 0.4329 - fscore: 0.2014 - val_loss: 1.4587 - val_acc: 0.3958 - val_fscore: 0.2013\n",
            "Epoch 41/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4141 - acc: 0.4382 - fscore: 0.2001 - val_loss: 1.4579 - val_acc: 0.4044 - val_fscore: 0.1866\n",
            "Epoch 42/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.4103 - acc: 0.4317 - fscore: 0.2037 - val_loss: 1.4637 - val_acc: 0.3958 - val_fscore: 0.2276\n",
            "Epoch 43/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.4058 - acc: 0.4375 - fscore: 0.2101 - val_loss: 1.4588 - val_acc: 0.4034 - val_fscore: 0.1775\n",
            "Epoch 44/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.4061 - acc: 0.4365 - fscore: 0.2031 - val_loss: 1.4527 - val_acc: 0.4063 - val_fscore: 0.1829\n",
            "Epoch 45/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3987 - acc: 0.4432 - fscore: 0.2114 - val_loss: 1.4501 - val_acc: 0.3996 - val_fscore: 0.1890\n",
            "Epoch 46/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3959 - acc: 0.4413 - fscore: 0.2074 - val_loss: 1.4480 - val_acc: 0.4101 - val_fscore: 0.1953\n",
            "Epoch 47/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3917 - acc: 0.4425 - fscore: 0.2175 - val_loss: 1.4447 - val_acc: 0.4082 - val_fscore: 0.1946\n",
            "Epoch 48/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3892 - acc: 0.4468 - fscore: 0.2099 - val_loss: 1.4483 - val_acc: 0.3996 - val_fscore: 0.2214\n",
            "Epoch 49/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3863 - acc: 0.4466 - fscore: 0.2184 - val_loss: 1.4555 - val_acc: 0.3996 - val_fscore: 0.2054\n",
            "Epoch 50/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3834 - acc: 0.4466 - fscore: 0.2148 - val_loss: 1.4403 - val_acc: 0.4130 - val_fscore: 0.2067\n",
            "Epoch 51/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3830 - acc: 0.4482 - fscore: 0.2191 - val_loss: 1.4402 - val_acc: 0.4120 - val_fscore: 0.1950\n",
            "Epoch 52/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3802 - acc: 0.4523 - fscore: 0.2152 - val_loss: 1.4413 - val_acc: 0.4073 - val_fscore: 0.2379\n",
            "Epoch 53/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3749 - acc: 0.4571 - fscore: 0.2227 - val_loss: 1.4388 - val_acc: 0.4120 - val_fscore: 0.2183\n",
            "Epoch 54/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3671 - acc: 0.4571 - fscore: 0.2196 - val_loss: 1.4467 - val_acc: 0.3977 - val_fscore: 0.2437\n",
            "Epoch 55/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.3685 - acc: 0.4557 - fscore: 0.2195 - val_loss: 1.4339 - val_acc: 0.4273 - val_fscore: 0.1985\n",
            "Epoch 56/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3650 - acc: 0.4561 - fscore: 0.2220 - val_loss: 1.4299 - val_acc: 0.4187 - val_fscore: 0.2044\n",
            "Epoch 57/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.3590 - acc: 0.4595 - fscore: 0.2248 - val_loss: 1.4308 - val_acc: 0.4178 - val_fscore: 0.2157\n",
            "Epoch 58/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3562 - acc: 0.4657 - fscore: 0.2290 - val_loss: 1.4319 - val_acc: 0.4187 - val_fscore: 0.2174\n",
            "Epoch 59/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3528 - acc: 0.4628 - fscore: 0.2387 - val_loss: 1.4257 - val_acc: 0.4264 - val_fscore: 0.2175\n",
            "Epoch 60/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3456 - acc: 0.4657 - fscore: 0.2342 - val_loss: 1.4226 - val_acc: 0.4168 - val_fscore: 0.1945\n",
            "Epoch 61/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3454 - acc: 0.4700 - fscore: 0.2335 - val_loss: 1.4257 - val_acc: 0.4187 - val_fscore: 0.2036\n",
            "Epoch 62/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3407 - acc: 0.4688 - fscore: 0.2341 - val_loss: 1.4195 - val_acc: 0.4207 - val_fscore: 0.2215\n",
            "Epoch 63/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3416 - acc: 0.4702 - fscore: 0.2398 - val_loss: 1.4216 - val_acc: 0.4197 - val_fscore: 0.2346\n",
            "Epoch 64/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3352 - acc: 0.4719 - fscore: 0.2398 - val_loss: 1.4181 - val_acc: 0.4207 - val_fscore: 0.2144\n",
            "Epoch 65/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3331 - acc: 0.4788 - fscore: 0.2477 - val_loss: 1.4201 - val_acc: 0.4178 - val_fscore: 0.2176\n",
            "Epoch 66/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3300 - acc: 0.4791 - fscore: 0.2447 - val_loss: 1.4199 - val_acc: 0.4168 - val_fscore: 0.2457\n",
            "Epoch 67/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3231 - acc: 0.4748 - fscore: 0.2474 - val_loss: 1.4234 - val_acc: 0.4207 - val_fscore: 0.2176\n",
            "Epoch 68/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.3238 - acc: 0.4798 - fscore: 0.2521 - val_loss: 1.4127 - val_acc: 0.4293 - val_fscore: 0.2326\n",
            "Epoch 69/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3205 - acc: 0.4894 - fscore: 0.2560 - val_loss: 1.4129 - val_acc: 0.4273 - val_fscore: 0.2046\n",
            "Epoch 70/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3179 - acc: 0.4836 - fscore: 0.2529 - val_loss: 1.4127 - val_acc: 0.4264 - val_fscore: 0.2237\n",
            "Epoch 71/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3110 - acc: 0.4915 - fscore: 0.2565 - val_loss: 1.4286 - val_acc: 0.4197 - val_fscore: 0.2197\n",
            "Epoch 72/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3060 - acc: 0.4877 - fscore: 0.2713 - val_loss: 1.4312 - val_acc: 0.4197 - val_fscore: 0.2123\n",
            "Epoch 73/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3017 - acc: 0.4910 - fscore: 0.2607 - val_loss: 1.4052 - val_acc: 0.4398 - val_fscore: 0.2413\n",
            "Epoch 74/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.3032 - acc: 0.4932 - fscore: 0.2684 - val_loss: 1.3986 - val_acc: 0.4388 - val_fscore: 0.2239\n",
            "Epoch 75/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2940 - acc: 0.5018 - fscore: 0.2770 - val_loss: 1.4116 - val_acc: 0.4359 - val_fscore: 0.2345\n",
            "Epoch 76/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2911 - acc: 0.4939 - fscore: 0.2768 - val_loss: 1.4022 - val_acc: 0.4369 - val_fscore: 0.2604\n",
            "Epoch 77/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2854 - acc: 0.5023 - fscore: 0.2830 - val_loss: 1.4087 - val_acc: 0.4321 - val_fscore: 0.2587\n",
            "Epoch 78/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2830 - acc: 0.5039 - fscore: 0.2792 - val_loss: 1.4051 - val_acc: 0.4388 - val_fscore: 0.2364\n",
            "Epoch 79/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2790 - acc: 0.5020 - fscore: 0.2922 - val_loss: 1.4025 - val_acc: 0.4455 - val_fscore: 0.2385\n",
            "Epoch 80/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2743 - acc: 0.5087 - fscore: 0.2898 - val_loss: 1.4003 - val_acc: 0.4417 - val_fscore: 0.2354\n",
            "Epoch 81/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2703 - acc: 0.5059 - fscore: 0.2947 - val_loss: 1.3992 - val_acc: 0.4312 - val_fscore: 0.2531\n",
            "Epoch 82/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2722 - acc: 0.4984 - fscore: 0.2975 - val_loss: 1.3914 - val_acc: 0.4312 - val_fscore: 0.2506\n",
            "Epoch 83/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.2677 - acc: 0.5111 - fscore: 0.3028 - val_loss: 1.3900 - val_acc: 0.4359 - val_fscore: 0.2359\n",
            "Epoch 84/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.2603 - acc: 0.5087 - fscore: 0.3036 - val_loss: 1.3912 - val_acc: 0.4407 - val_fscore: 0.2589\n",
            "Epoch 85/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.2546 - acc: 0.5159 - fscore: 0.3158 - val_loss: 1.3903 - val_acc: 0.4369 - val_fscore: 0.2661\n",
            "Epoch 86/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2522 - acc: 0.5190 - fscore: 0.3083 - val_loss: 1.3891 - val_acc: 0.4455 - val_fscore: 0.2506\n",
            "Epoch 87/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2436 - acc: 0.5283 - fscore: 0.3087 - val_loss: 1.3892 - val_acc: 0.4455 - val_fscore: 0.2486\n",
            "Epoch 88/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2450 - acc: 0.5212 - fscore: 0.3177 - val_loss: 1.3920 - val_acc: 0.4436 - val_fscore: 0.2582\n",
            "Epoch 89/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.2461 - acc: 0.5149 - fscore: 0.3168 - val_loss: 1.4018 - val_acc: 0.4388 - val_fscore: 0.2704\n",
            "Epoch 90/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2370 - acc: 0.5204 - fscore: 0.3243 - val_loss: 1.3894 - val_acc: 0.4436 - val_fscore: 0.2684\n",
            "Epoch 91/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.2410 - acc: 0.5240 - fscore: 0.3285 - val_loss: 1.3896 - val_acc: 0.4350 - val_fscore: 0.2697\n",
            "Epoch 92/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.2302 - acc: 0.5317 - fscore: 0.3296 - val_loss: 1.3957 - val_acc: 0.4312 - val_fscore: 0.2767\n",
            "Epoch 93/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.2283 - acc: 0.5307 - fscore: 0.3353 - val_loss: 1.3829 - val_acc: 0.4426 - val_fscore: 0.2483\n",
            "Epoch 94/100\n",
            "4183/4183 [==============================] - 7s 2ms/sample - loss: 1.2199 - acc: 0.5336 - fscore: 0.3433 - val_loss: 1.4052 - val_acc: 0.4321 - val_fscore: 0.2786\n",
            "Epoch 95/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2170 - acc: 0.5360 - fscore: 0.3447 - val_loss: 1.3924 - val_acc: 0.4359 - val_fscore: 0.2516\n",
            "Epoch 96/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.2122 - acc: 0.5329 - fscore: 0.3466 - val_loss: 1.3826 - val_acc: 0.4407 - val_fscore: 0.2646\n",
            "Epoch 97/100\n",
            "4183/4183 [==============================] - 6s 2ms/sample - loss: 1.2047 - acc: 0.5436 - fscore: 0.3525 - val_loss: 1.3863 - val_acc: 0.4426 - val_fscore: 0.2548\n",
            "Epoch 98/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.2013 - acc: 0.5439 - fscore: 0.3521 - val_loss: 1.3881 - val_acc: 0.4302 - val_fscore: 0.2738\n",
            "Epoch 99/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.1995 - acc: 0.5448 - fscore: 0.3608 - val_loss: 1.3864 - val_acc: 0.4321 - val_fscore: 0.2650\n",
            "Epoch 100/100\n",
            "4183/4183 [==============================] - 6s 1ms/sample - loss: 1.1917 - acc: 0.5501 - fscore: 0.3685 - val_loss: 1.3829 - val_acc: 0.4398 - val_fscore: 0.2670\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em395OiXoPbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lzkY7UPn8Ca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Test_kq = model.predict(X_test, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE3Li0q4rrGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds1 = X_Test_kq.argmax(axis=1)\n",
        "Y_test_kq = preds1.astype(int).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94S9F7ect6-x",
        "colab_type": "code",
        "outputId": "13515570-b442-489c-9c3b-879cba0287a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Y_test_kq[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vccD_o8WuEx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0beIIoJxuII",
        "colab_type": "code",
        "outputId": "53458720-3608-423b-8f52-e3070b351b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "filename[1006]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PAEP-000020.wav'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIh6WlJtuF9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/gdrive/My Drive/Public_Test/Testfile.csv') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    next(csv_reader)    # bỏ qua dòng đầu tiên của file csv\n",
        "    with open('/content/gdrive/My Drive/Public_Test/label.csv', mode='w') as file:\n",
        "        writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        lct = 0\n",
        "        for row in csv_reader:\n",
        "          writer.writerow([row[0],Y_test_kq[lct]])\n",
        "          lct += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcV59JreJARE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLuPODOHrVw6",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMQZ_aPpO4-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/gdrive/My Drive/Public_Test/label.csv', mode='w') as file:\n",
        "    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    lct = 0\n",
        "    for row in test_reader:\n",
        "        writer.writerow([filename[i],Y_test[lct]])\n",
        "        lct += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyqKMd4TMt5D",
        "colab_type": "text"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPlDx83XrMMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At7HO9AnUc03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the paramter grid for C from 0.001 to 10, gamma from 0.001 to 10\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state = 42, shuffle = True)\n",
        "\n",
        "C_grid = [0.001, 0.01, 0.1, 1, 10]\n",
        "gamma_grid = [0.001, 0.01, 0.1, 1, 10]\n",
        "param_grid = {'C': C_grid, 'gamma' : gamma_grid}\n",
        "\n",
        "grid = GridSearchCV(SVC(kernel='rbf'), param_grid, cv = 3, scoring = \"accuracy\")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Find the best model\n",
        "print(grid.best_score_)\n",
        "\n",
        "print(grid.best_params_)\n",
        "\n",
        "print(grid.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJKXbtvNVSWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = SVC(kernel = 'rbf',C=1,gamma=0.001,decision_function_shape='ovr')\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(accuracy_score(clf.predict(X_val), y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7_ncGo31L9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = clf.predict(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84Tz6uLninii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = 0\n",
        "for i in range(label.shape[0]):\n",
        "  if (label[i] == y_val[i]):\n",
        "    count +=1;\n",
        "print(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygdX6vrTYoaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrtxl9OjWdlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd '/content/gdrive/My Drive/Handout (1)'\n",
        "! ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glko-EAwjjDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTJAavTMkDd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yr0prMSJhAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uCAa575rODh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install python_speech_features"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}